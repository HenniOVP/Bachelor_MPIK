{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import Waveform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import pickle\n",
    "import matplotlib.dates as md\n",
    "import datetime as dt\n",
    "import time\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import zipfile\n",
    "import datetime\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_from_folder_instad_zip = True\n",
    "\n",
    "zip_to_read = \"Z:\\\\MPIK\\\\recordings_until_20180320.zip\"\n",
    "folder_to_read = \"Z:\\\\MPIK\\\\recordings_until_20180320\\\\LeCroyHDO\\\\\"\n",
    "#folder_to_read = \"Z:\\\\MPIK\\\\rec_selection\\\\\"\n",
    "\n",
    "pkl_to_write = \"data_from_zip_{}.pkl\".format(zip_to_read.split('_')[-1].split('.')[0])\n",
    "json_to_write = \"data_from_zip_{}.json\".format(zip_to_read.split('_')[-1].split('.')[0])\n",
    "\n",
    "channels_to_read = ['C1', 'C2', 'C3']\n",
    "smoothing_window = [32, 4096*4, 4096*4]\n",
    "modes = ['raw', 'diff1', 'diff2']\n",
    "\n",
    "use_moving_average_instead_of_windowed_average = False\n",
    "\n",
    "status_print_holdoff = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the needed data structures\n",
    "WF_keys = ['unixtime']\n",
    "for chan in channels_to_read:\n",
    "    for mode in modes:\n",
    "        WF_keys.append('{}_{}_max'.format(chan, mode))\n",
    "        WF_keys.append('{}_{}_max_time'.format(chan, mode))\n",
    "        WF_keys.append('{}_{}_min'.format(chan, mode))\n",
    "        WF_keys.append('{}_{}_min_time'.format(chan, mode))\n",
    "\n",
    "WF_data = {}\n",
    "for key in WF_keys:\n",
    "    WF_data[key] = []\n",
    "\n",
    "\n",
    "zip_name_list = []\n",
    "if read_from_folder_instad_zip:\n",
    "    zip_name_list = glob(folder_to_read+'*'+channels_to_read[0]+'.bytes')\n",
    "else:\n",
    "    with zipfile.ZipFile(zip_to_read, 'r') as zf:\n",
    "        # get the list of files in the zip\n",
    "        zip_name_list = zf.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_WFs_for_timestamp(timestamp):\n",
    "    timestamp = str(timestamp)\n",
    "    \n",
    "    extracted_WFs = []\n",
    "    # open the zip file\n",
    "    with zipfile.ZipFile(zip_to_read, 'r') as zf:\n",
    "        # start the extraction process\n",
    "        files_to_extract = []\n",
    "        for name in zip_name_list:\n",
    "            if timestamp in name:\n",
    "                files_to_extract.append(name)\n",
    "\n",
    "        files_to_extract = sorted(files_to_extract)\n",
    "        for name in files_to_extract:\n",
    "            try:\n",
    "                data = zf.read(name)\n",
    "                extracted_WFs.append(Waveform.Waveform(data))\n",
    "            except OSError as e:\n",
    "                print(\"An OSError with the following message occured: {}\".format(e))\n",
    "                print(\"The that was to be extracted was: {}\".format(name))\n",
    "                print(\"Continuing anyways.\")\n",
    "    return extracted_WFs\n",
    "\n",
    "def extract_WFs_from_zip(list_files):\n",
    "    extracted_WFs = []\n",
    "    with zipfile.ZipFile(zip_to_read, 'r') as zf:\n",
    "        for name in list_files:\n",
    "            try:\n",
    "                data = zf.read(name)\n",
    "                extracted_WFs.append(Waveform.Waveform(data))\n",
    "            except OSError as e:\n",
    "                print(\"An OSError with the following message occured: {}\".format(e))\n",
    "                print(\"The that was to be extracted was: {}\".format(name))\n",
    "                print(\"Continuing anyways.\")\n",
    "    return extracted_WFs\n",
    "\n",
    "def extract_WFs_from_files(file_list):\n",
    "    extracted_WFs = []\n",
    "    for file in file_list:\n",
    "        with open(file, \"rb\") as f:\n",
    "            raw_WF = f.read()\n",
    "        try:\n",
    "            extracted_WFs.append(Waveform.Waveform(raw_WF))\n",
    "        except Exception as e:\n",
    "            # this may happen when an event was not completly written and the data is thus shorter than expected\n",
    "            print(\"WARN: Skipping event!\\tError while parsing file {}\".format(file))\n",
    "            print(\"Following exception occured: {}\".format(e))\n",
    "    return extracted_WFs\n",
    "\n",
    "# function to do a moving average over the data\n",
    "def avg_smoother(x, y, width):\n",
    "    window = np.ones(width)/width\n",
    "    y_smooth = np.convolve(y, window, mode='same')\n",
    "    return x, y_smooth\n",
    "\n",
    "# function to reduce the array size by averaging over fixed parts\n",
    "def avg_reducer(x, y, width):\n",
    "    # see: https://stackoverflow.com/a/26639037\n",
    "    x = x[:len(x)//width * width].reshape(-1, width).mean(axis=1)\n",
    "    y = y[:len(y)//width * width].reshape(-1, width).mean(axis=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aproximate number of events to read: 28315.00 \n",
      "Progress: 99.947 [%]\tEstimated time left: 0.07 [min]\tRead speed: 221.6 [Events/min]]]\r"
     ]
    }
   ],
   "source": [
    "events_to_read = len(zip_name_list)\n",
    "print(\"Aproximate number of events to read: {:.2f} \".format(events_to_read))\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(len(zip_name_list)):\n",
    "    \n",
    "    # print the status first\n",
    "    if (i % status_print_holdoff) == 0:\n",
    "        if i == 0:\n",
    "            continue\n",
    "        current_step_time = time.time() - start_time\n",
    "        estimated_time_per_event = current_step_time / status_print_holdoff\n",
    "        estimated_left_over_time = (events_to_read - i)*estimated_time_per_event /60\n",
    "        read_speed = 60*1/estimated_time_per_event\n",
    "        message = \"Progress: {:.3f} [%]\\tEstimated time left: {:.2f} [min]\\tRead speed: {:0.1f} [Events/min]\"\n",
    "        message = message.format(100*i/events_to_read, estimated_left_over_time, read_speed)\n",
    "        print(message, end='\\r')\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # check that the file is a measruement\n",
    "    if \".bytes\" in zip_name_list[i]:\n",
    "        file_name = zip_name_list[i]\n",
    "        unixtime = float(file_name.split('_')[-2])\n",
    "        # check that we haven't already read the event\n",
    "        if unixtime in WF_data['unixtime']:\n",
    "            continue\n",
    "        \n",
    "        # find out which files need to be extracted\n",
    "        files_to_extract = []\n",
    "        for chan in channels_to_read:\n",
    "            files_to_extract.append(file_name.replace(file_name.split('_')[-1].split('.')[0], chan))\n",
    "        \n",
    "        try:\n",
    "            if read_from_folder_instad_zip:\n",
    "                WFs = extract_WFs_from_files(files_to_extract)\n",
    "            else:\n",
    "                WFs = extract_WFs_from_zip(files_to_extract)\n",
    "        except Exception as e:\n",
    "            # this may happen when an event was not completly written and the data is thus shorter than expected\n",
    "            print(\"WARN: Skipping event!\\tError while parsing following event files: {}\".format(files_to_extract))\n",
    "            print(\"Following exception occured: {}\".format(e))\n",
    "            continue\n",
    "        \n",
    "        # do the analysis on the current WFs\n",
    "        # smoothing\n",
    "        for i in range(len(smoothing_window)):\n",
    "            if use_moving_average_instead_of_windowed_average:\n",
    "                WFs[i].time, WFs[i].data = avg_smoother(WFs[i].time, WFs[i].data, smoothing_window[i])\n",
    "            else:\n",
    "                WFs[i].time, WFs[i].data = avg_reducer(WFs[i].time, WFs[i].data, smoothing_window[i])\n",
    "        \n",
    "        # calculate diff 1 and 2\n",
    "        diffs = {\n",
    "            'diff1': [],\n",
    "            'diff2': []\n",
    "        }\n",
    "        for i in range(len(smoothing_window)):\n",
    "            grad = np.gradient(WFs[i].data)\n",
    "            diffs['diff1'].append(grad)\n",
    "            diffs['diff2'].append(np.gradient(grad))\n",
    "            \n",
    "        # calculate max and min\n",
    "        # extract data from all wavforms from this event\n",
    "        WF_data['unixtime'].append(unixtime)\n",
    "        for WF in WFs:\n",
    "            index = WF.get_channel() - 1\n",
    "            chan = \"C{}\".format(WF.get_channel())\n",
    "            for mode in modes:\n",
    "                data_for_mode = 0\n",
    "                if mode == 'raw':\n",
    "                    data_for_mode = WF.data\n",
    "                elif mode == 'diff1':\n",
    "                    data_for_mode = diffs['diff1'][index]\n",
    "                elif mode == 'diff2':\n",
    "                    data_for_mode = diffs['diff2'][index]\n",
    "                else:\n",
    "                    raise(RuntimeError(\"Mode not supported! Aborting!\"))\n",
    "                \n",
    "                WF_data['{}_{}_max'.format(chan, mode)].append(data_for_mode.max())\n",
    "                WF_data['{}_{}_max_time'.format(chan, mode)].append(WF.time[data_for_mode.argmax()])\n",
    "                WF_data['{}_{}_min'.format(chan, mode)].append(data_for_mode.min())\n",
    "                WF_data['{}_{}_min_time'.format(chan, mode)].append(WF.time[data_for_mode.argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving json to disk\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'WF_data_lists_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f121e9eb5a3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Saving json to disk\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_to_write\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWF_data_lists_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# convert list to np.arrays and save as pkl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'WF_data_lists_1' is not defined"
     ]
    }
   ],
   "source": [
    "# save data\n",
    "print(\"Saving json to disk\")\n",
    "with open(json_to_write, 'w') as outfile:\n",
    "    json.dump(WF_data_lists_1, outfile)\n",
    "    \n",
    "# convert list to np.arrays and save as pkl\n",
    "print(\"Converting read lists to numpy arrays\")\n",
    "for key in WF_keys:\n",
    "    WF_data[key] = np.asarray(WF_data[key])\n",
    "\n",
    "print(\"Saving pkl to disk\")\n",
    "with open(pkl_to_write, 'wb') as f:\n",
    "    pickle.dump(WF_data, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unixtime 28314\n",
      "C1_raw_max 0\n",
      "C1_raw_max_time 0\n",
      "C1_raw_min 0\n",
      "C1_raw_min_time 0\n",
      "C1_diff1_max 0\n",
      "C1_diff1_max_time 0\n",
      "C1_diff1_min 0\n",
      "C1_diff1_min_time 0\n",
      "C1_diff2_max 0\n",
      "C1_diff2_max_time 0\n",
      "C1_diff2_min 0\n",
      "C1_diff2_min_time 0\n",
      "C2_raw_max 28314\n",
      "C2_raw_max_time 28314\n",
      "C2_raw_min 28314\n",
      "C2_raw_min_time 28314\n",
      "C2_diff1_max 28314\n",
      "C2_diff1_max_time 28314\n",
      "C2_diff1_min 28314\n",
      "C2_diff1_min_time 28314\n",
      "C2_diff2_max 28314\n",
      "C2_diff2_max_time 28314\n",
      "C2_diff2_min 28314\n",
      "C2_diff2_min_time 28314\n",
      "C3_raw_max 56628\n",
      "C3_raw_max_time 56628\n",
      "C3_raw_min 56628\n",
      "C3_raw_min_time 56628\n",
      "C3_diff1_max 56628\n",
      "C3_diff1_max_time 56628\n",
      "C3_diff1_min 56628\n",
      "C3_diff1_min_time 56628\n",
      "C3_diff2_max 56628\n",
      "C3_diff2_max_time 56628\n",
      "C3_diff2_min 56628\n",
      "C3_diff2_min_time 56628\n"
     ]
    }
   ],
   "source": [
    "for key in WF_data.keys():\n",
    "    print(key, len(WF_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
